#!/usr/bin/env python3
"""
ç¤ºä¾‹ï¼šå¦‚ä½•ä½¿ç”¨ä¸åŒçš„è°ƒåº¦å™¨æ¨¡å¼

è¿™ä¸ªæ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ç»Ÿä¸€è°ƒåº¦å™¨å’Œåˆ†ç¦»è°ƒåº¦å™¨æ¥å¤„ç†è®­ç»ƒå’Œè¯„ä¼°ä»»åŠ¡ã€‚
"""

import json
import pika
import asyncio
import ray
from training_platform.configs.settings import settings

def send_training_task():
    """å‘é€è®­ç»ƒä»»åŠ¡è¯·æ±‚"""
    print("ğŸ“¤ å‘é€è®­ç»ƒä»»åŠ¡è¯·æ±‚...")
    
    training_message = {
        "task_type": "training",
        "task_id": 1001,
        "user_id": 1,
        "dataset_uuid": "lerobot/aloha_sim_insertion_human",
        "model_type": "act",
        "config": {
            "policy": {"type": "act"},
            "env": {"type": "aloha"},
            "dataset": {"repo_id": "lerobot/aloha_sim_insertion_human"},
            "steps": 1000,
            "save_freq": 250,
            "batch_size": 8,
        }
    }
    
    connection = pika.BlockingConnection(pika.ConnectionParameters(settings.RABBITMQ_SERVER))
    channel = connection.channel()
    
    channel.basic_publish(
        exchange=settings.RABBIT_EXCHANGE_NAME,
        routing_key=settings.RABBIT_REQUEST_BINDING_KEY,
        body=json.dumps(training_message)
    )
    
    connection.close()
    print("âœ… è®­ç»ƒä»»åŠ¡å·²å‘é€")

def send_evaluation_task():
    """å‘é€è¯„ä¼°ä»»åŠ¡è¯·æ±‚"""
    print("ğŸ“¤ å‘é€è¯„ä¼°ä»»åŠ¡è¯·æ±‚...")
    
    evaluation_message = {
        "task_type": "evaluation",
        "task_id": 2001,
        "user_id": 1,
        "model_uuid": "lerobot/act_aloha_sim_insertion_human",
        "model_type": "act",
        "env_config": {
            "type": "aloha",
            "task": "AlohaInsertion-v0",
            "fps": 50,
            "episode_length": 400,
            "obs_type": "pixels_agent_pos",
            "render_mode": "rgb_array"
        },
        "eval_config": {
            "n_episodes": 10,
            "batch_size": 1,
            "use_async_envs": False
        },
        "seed": 1000,
        "max_episodes_rendered": 5,
        "return_episode_data": False
    }
    
    connection = pika.BlockingConnection(pika.ConnectionParameters(settings.RABBITMQ_SERVER))
    channel = connection.channel()
    
    channel.basic_publish(
        exchange=settings.RABBIT_EXCHANGE_NAME,
        routing_key=settings.RABBIT_REQUEST_BINDING_KEY,
        body=json.dumps(evaluation_message)
    )
    
    connection.close()
    print("âœ… è¯„ä¼°ä»»åŠ¡å·²å‘é€")

async def test_unified_scheduler():
    """æµ‹è¯•ç»Ÿä¸€è°ƒåº¦å™¨"""
    print("\nğŸ§ª æµ‹è¯•ç»Ÿä¸€è°ƒåº¦å™¨æ¨¡å¼")
    print("=" * 50)
    
    # åˆå§‹åŒ– Ray
    if not ray.is_initialized():
        ray.init()
    
    # å¯åŠ¨ç»Ÿä¸€è°ƒåº¦å™¨
    from training_platform.scheduler.scheduler_actor import Scheduler
    scheduler = Scheduler.options(name="TestUnifiedScheduler").remote()
    scheduler.run.remote()
    
    # ç­‰å¾…è°ƒåº¦å™¨å¯åŠ¨
    await asyncio.sleep(2)
    
    # å‘é€æ··åˆä»»åŠ¡
    print("ğŸ“¤ å‘é€æ··åˆä»»åŠ¡åˆ°ç»Ÿä¸€è°ƒåº¦å™¨...")
    
    # å‘é€è®­ç»ƒä»»åŠ¡
    training_task = {
        "task_type": "training",
        "task_id": 3001,
        "user_id": 1,
        "dataset_uuid": "lerobot/aloha_sim_insertion_human",
        "model_type": "act",
        "config": {
            "policy": {"type": "act"},
            "env": {"type": "aloha"},
            "dataset": {"repo_id": "lerobot/aloha_sim_insertion_human"},
            "steps": 100,
            "save_freq": 25,
            "batch_size": 8,
        }
    }
    
    await scheduler.add_task.remote(training_task)
    
    # å‘é€è¯„ä¼°ä»»åŠ¡
    evaluation_task = {
        "task_type": "evaluation",
        "task_id": 3002,
        "user_id": 1,
        "model_uuid": "lerobot/act_aloha_sim_insertion_human",
        "model_type": "act",
        "env_config": {
            "type": "aloha",
            "task": "AlohaInsertion-v0",
            "fps": 50,
            "episode_length": 400,
            "obs_type": "pixels_agent_pos",
            "render_mode": "rgb_array"
        },
        "eval_config": {
            "n_episodes": 5,
            "batch_size": 1,
            "use_async_envs": False
        },
        "seed": 42,
        "max_episodes_rendered": 3,
        "return_episode_data": False
    }
    
    await scheduler.add_task.remote(evaluation_task)
    
    print("âœ… æ··åˆä»»åŠ¡å·²å‘é€åˆ°ç»Ÿä¸€è°ƒåº¦å™¨")
    
    # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ä»»åŠ¡æ‰§è¡Œ
    await asyncio.sleep(10)
    
    # æ¸…ç†
    ray.kill(scheduler)

async def test_separate_schedulers():
    """æµ‹è¯•åˆ†ç¦»è°ƒåº¦å™¨"""
    print("\nğŸ§ª æµ‹è¯•åˆ†ç¦»è°ƒåº¦å™¨æ¨¡å¼")
    print("=" * 50)
    
    # åˆå§‹åŒ– Ray
    if not ray.is_initialized():
        ray.init()
    
    # å¯åŠ¨åˆ†ç¦»çš„è°ƒåº¦å™¨
    from training_platform.scheduler.scheduler_actor import TrainingScheduler, EvaluationScheduler
    
    training_scheduler = TrainingScheduler.options(name="TestTrainingScheduler").remote()
    evaluation_scheduler = EvaluationScheduler.options(name="TestEvaluationScheduler").remote()
    
    training_scheduler.run.remote()
    evaluation_scheduler.run.remote()
    
    # ç­‰å¾…è°ƒåº¦å™¨å¯åŠ¨
    await asyncio.sleep(2)
    
    # å‘é€ä»»åŠ¡åˆ°å„è‡ªçš„è°ƒåº¦å™¨
    print("ğŸ“¤ å‘é€ä»»åŠ¡åˆ°åˆ†ç¦»è°ƒåº¦å™¨...")
    
    # è®­ç»ƒä»»åŠ¡
    training_task = {
        "task_id": 4001,
        "user_id": 1,
        "dataset_uuid": "lerobot/aloha_sim_insertion_human",
        "model_type": "act",
        "config": {
            "policy": {"type": "act"},
            "env": {"type": "aloha"},
            "dataset": {"repo_id": "lerobot/aloha_sim_insertion_human"},
            "steps": 100,
            "save_freq": 25,
            "batch_size": 8,
        }
    }
    
    await training_scheduler.add_task.remote(training_task)
    
    # è¯„ä¼°ä»»åŠ¡
    evaluation_task = {
        "task_id": 4002,
        "user_id": 1,
        "model_uuid": "lerobot/act_aloha_sim_insertion_human",
        "model_type": "act",
        "env_config": {
            "type": "aloha",
            "task": "AlohaInsertion-v0",
            "fps": 50,
            "episode_length": 400,
            "obs_type": "pixels_agent_pos",
            "render_mode": "rgb_array"
        },
        "eval_config": {
            "n_episodes": 5,
            "batch_size": 1,
            "use_async_envs": False
        },
        "seed": 42,
        "max_episodes_rendered": 3,
        "return_episode_data": False
    }
    
    await evaluation_scheduler.add_task.remote(evaluation_task)
    
    print("âœ… ä»»åŠ¡å·²å‘é€åˆ°åˆ†ç¦»è°ƒåº¦å™¨")
    
    # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ä»»åŠ¡æ‰§è¡Œ
    await asyncio.sleep(10)
    
    # æ¸…ç†
    ray.kill(training_scheduler)
    ray.kill(evaluation_scheduler)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è°ƒåº¦å™¨ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # æµ‹è¯•åŸºæœ¬æ¶ˆæ¯å‘é€
    print("\nğŸ“¤ æµ‹è¯•åŸºæœ¬æ¶ˆæ¯å‘é€...")
    send_training_task()
    send_evaluation_task()
    
    # æµ‹è¯•ç»Ÿä¸€è°ƒåº¦å™¨
    asyncio.run(test_unified_scheduler())
    
    # æµ‹è¯•åˆ†ç¦»è°ƒåº¦å™¨
    asyncio.run(test_separate_schedulers())
    
    print("\nğŸ“‹ è°ƒåº¦å™¨æ¨¡å¼è¯´æ˜ï¼š")
    print("1. ç»Ÿä¸€è°ƒåº¦å™¨ (Unified Scheduler):")
    print("   - åŒæ—¶å¤„ç†è®­ç»ƒå’Œè¯„ä¼°ä»»åŠ¡")
    print("   - å¹¶è¡Œæ‰§è¡Œï¼Œèµ„æºå…±äº«")
    print("   - é€‚åˆèµ„æºæœ‰é™çš„ç¯å¢ƒ")
    print()
    print("2. åˆ†ç¦»è°ƒåº¦å™¨ (Separate Schedulers):")
    print("   - è®­ç»ƒå’Œè¯„ä¼°ä»»åŠ¡åˆ†åˆ«å¤„ç†")
    print("   - ç‹¬ç«‹èµ„æºåˆ†é…")
    print("   - é€‚åˆå¤§è§„æ¨¡éƒ¨ç½²")
    print()
    print("3. æ¶ˆæ¯æ ¼å¼ï¼š")
    print("   - è®­ç»ƒä»»åŠ¡ï¼šéœ€è¦ dataset_uuid, model_type, config")
    print("   - è¯„ä¼°ä»»åŠ¡ï¼šéœ€è¦ model_uuid, model_type, env_config, eval_config")
    print("   - task_type å­—æ®µç”¨äºåŒºåˆ†ä»»åŠ¡ç±»å‹")

if __name__ == "__main__":
    main() 