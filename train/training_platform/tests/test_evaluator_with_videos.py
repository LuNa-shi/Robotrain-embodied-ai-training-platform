#!/usr/bin/env python3
"""
ä¸“é—¨ç”¨äºç”Ÿæˆè¯„ä¼°è§†é¢‘çš„æµ‹è¯•è„šæœ¬
ä¼šå°†ç”Ÿæˆçš„è§†é¢‘ä¿å­˜åˆ° outputs æ–‡ä»¶å¤¹ä¸­
"""

import sys
import os
import asyncio
import tempfile
import shutil
import json
import time
from pathlib import Path
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def setup_video_environment():
    """è®¾ç½®è§†é¢‘ç”Ÿæˆç¯å¢ƒ"""
    print("ğŸ¬ è®¾ç½®è§†é¢‘ç”Ÿæˆç¯å¢ƒ...")
    
    # åˆ›å»º outputs æ–‡ä»¶å¤¹
    outputs_dir = Path("./outputs")
    outputs_dir.mkdir(exist_ok=True)
    print(f"âœ… è¾“å‡ºç›®å½•åˆ›å»º: {outputs_dir}")
    
    # åˆ›å»ºè¯„ä¼°è§†é¢‘å­ç›®å½•
    evaluation_videos_dir = outputs_dir / "evaluation_videos"
    evaluation_videos_dir.mkdir(exist_ok=True)
    print(f"âœ… è¯„ä¼°è§†é¢‘ç›®å½•åˆ›å»º: {evaluation_videos_dir}")
    
    # åˆ›å»ºè¯„ä¼°ç»“æœå­ç›®å½•
    evaluation_results_dir = outputs_dir / "evaluation_results"
    evaluation_results_dir.mkdir(exist_ok=True)
    print(f"âœ… è¯„ä¼°ç»“æœç›®å½•åˆ›å»º: {evaluation_results_dir}")
    
    return outputs_dir, evaluation_videos_dir, evaluation_results_dir

def copy_videos_to_outputs(source_dir: Path, target_dir: Path, task_name: str) -> list:
    """å¤åˆ¶è§†é¢‘æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•"""
    copied_videos = []
    
    try:
        videos_dir = source_dir / "videos"
        if videos_dir.exists():
            video_files = list(videos_dir.glob("*.mp4"))
            print(f"ğŸ“¹ å‘ç° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            
            for i, video_file in enumerate(video_files):
                # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
                timestamp = int(time.time())
                output_filename = f"{task_name}_episode_{i}_{timestamp}.mp4"
                output_path = target_dir / output_filename
                
                # å¤åˆ¶è§†é¢‘æ–‡ä»¶
                shutil.copy2(video_file, output_path)
                copied_videos.append(output_path)
                print(f"âœ… è§†é¢‘å·²ä¿å­˜: {output_path}")
                
        else:
            print("âš ï¸  æœªæ‰¾åˆ°è§†é¢‘ç›®å½•")
            
    except Exception as e:
        print(f"âŒ å¤åˆ¶è§†é¢‘æ–‡ä»¶å¤±è´¥: {e}")
    
    return copied_videos

def save_evaluation_results(results: Dict[str, Any], target_dir: Path, task_name: str):
    """ä¿å­˜è¯„ä¼°ç»“æœåˆ°JSONæ–‡ä»¶"""
    try:
        timestamp = int(time.time())
        results_filename = f"{task_name}_results_{timestamp}.json"
        results_path = target_dir / results_filename
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜: {results_path}")
        return results_path
        
    except Exception as e:
        print(f"âŒ ä¿å­˜è¯„ä¼°ç»“æœå¤±è´¥: {e}")
        return None

async def test_direct_evaluation_with_videos():
    """æµ‹è¯•ç›´æ¥è¯„ä¼°è°ƒç”¨å¹¶ç”Ÿæˆè§†é¢‘"""
    print("\nğŸ¬ æµ‹è¯•ç›´æ¥è¯„ä¼°è°ƒç”¨ï¼ˆç”Ÿæˆè§†é¢‘ï¼‰...")
    
    try:
        from training_platform.evaluator.evaluator_logic import run_lerobot_evaluation
        
        # è®¾ç½®ç¯å¢ƒ
        outputs_dir, video_dir, results_dir = setup_video_environment()
        
        # é…ç½® - å¢åŠ å‰§é›†æ•°å’Œæ¸²æŸ“æ•°é‡
        model_path = "lerobot/act_aloha_sim_insertion_human"
        env_config = {
            "type": "aloha",
            "task": "AlohaInsertion-v0",
            "fps": 50,
            "episode_length": 400,
            "obs_type": "pixels_agent_pos",
            "render_mode": "rgb_array"  # ç¡®ä¿æ¸²æŸ“æ¨¡å¼æ­£ç¡®
        }
        eval_config = {
            "n_episodes": 5,  # å¢åŠ å‰§é›†æ•°
            "batch_size": 1,
            "use_async_envs": False
        }
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            output_dir = str(Path(temp_dir) / "eval_output")
            
            print(f"ğŸš€ å¼€å§‹è¯„ä¼°å¹¶ç”Ÿæˆè§†é¢‘...")
            print(f"  æ¨¡å‹: {model_path}")
            print(f"  å‰§é›†æ•°: {eval_config['n_episodes']}")
            print(f"  æ¸²æŸ“å‰§é›†æ•°: 5")
            print(f"  ä¸´æ—¶è¾“å‡ºç›®å½•: {output_dir}")
            
            # åœ¨çº¿ç¨‹ä¸­è¿è¡Œè¯„ä¼°
            results = await asyncio.to_thread(
                run_lerobot_evaluation,
                model_path=model_path,
                env_config=env_config,
                eval_config=eval_config,
                output_dir=output_dir,
                seed=1000,
                max_episodes_rendered=5,  # æ¸²æŸ“æ‰€æœ‰å‰§é›†
                return_episode_data=False
            )
            
            print("âœ… è¯„ä¼°å®Œæˆï¼")
            
            # ä¿å­˜è¯„ä¼°ç»“æœ
            save_evaluation_results(results, results_dir, "direct_evaluation")
            
            # å¤åˆ¶è§†é¢‘åˆ°è¾“å‡ºç›®å½•
            copied_videos = copy_videos_to_outputs(
                Path(output_dir), video_dir, "direct_evaluation"
            )
            
            # æ‰“å°è¯„ä¼°ç»“æœ
            if "aggregated" in results:
                aggregated = results["aggregated"]
                print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
                print(f"  å¹³å‡æ€»å¥–åŠ±: {aggregated['avg_sum_reward']:.4f}")
                print(f"  æˆåŠŸç‡: {aggregated['pc_success']:.2f}%")
                print(f"  è¯„ä¼°æ—¶é—´: {aggregated['eval_s']:.2f} ç§’")
                print(f"  ç”Ÿæˆè§†é¢‘æ•°é‡: {len(copied_videos)}")
                
                # æ‰“å°å„å‰§é›†ç»“æœ
                print(f"\nğŸ“‹ å„å‰§é›†è¯¦ç»†ç»“æœ:")
                for i, episode in enumerate(results.get("per_episode", [])):
                    print(f"  å‰§é›† {i}: æ€»å¥–åŠ±={episode.get('sum_reward', 0):.4f}, "
                          f"æœ€å¤§å¥–åŠ±={episode.get('max_reward', 0):.4f}, "
                          f"æˆåŠŸ={episode.get('success', False)}")
            
            # æ£€æŸ¥å…¶ä»–è¾“å‡ºæ–‡ä»¶
            eval_info_file = Path(output_dir) / "eval_info.json"
            if eval_info_file.exists():
                print(f"âœ… è¯„ä¼°ä¿¡æ¯æ–‡ä»¶å·²ç”Ÿæˆ: {eval_info_file}")
                # ä¹Ÿå¤åˆ¶è¯„ä¼°ä¿¡æ¯æ–‡ä»¶
                eval_info_target = results_dir / f"direct_evaluation_info_{int(time.time())}.json"
                shutil.copy2(eval_info_file, eval_info_target)
                print(f"âœ… è¯„ä¼°ä¿¡æ¯å·²ä¿å­˜: {eval_info_target}")
        
        return True, copied_videos, results
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, [], {}

def test_task_model():
    """æµ‹è¯•è¯„ä¼°ä»»åŠ¡æ¨¡å‹"""
    print("\nğŸ§ª æµ‹è¯•è¯„ä¼°ä»»åŠ¡æ¨¡å‹...")
    
    try:
        from training_platform.common.task_models import EvaluationTask
        
        # åˆ›å»ºè¯„ä¼°ä»»åŠ¡
        eval_task = EvaluationTask(
            task_id=999,
            user_id=1,
            model_uuid="lerobot/act_aloha_sim_insertion_human",
            model_type="act",
            env_config={
                "type": "aloha",
                "task": "AlohaInsertion-v0",
                "fps": 50,
                "episode_length": 400,
                "obs_type": "pixels_agent_pos",
                "render_mode": "rgb_array"
            },
            eval_config={
                "n_episodes": 5,
                "batch_size": 1,
                "use_async_envs": False
            },
            seed=1000,
            max_episodes_rendered=5,
            return_episode_data=False
        )
        
        print(f"âœ… è¯„ä¼°ä»»åŠ¡åˆ›å»ºæˆåŠŸ:")
        print(f"  ä»»åŠ¡ ID: {eval_task.task_id}")
        print(f"  æ¨¡å‹: {eval_task.model_uuid}")
        print(f"  ç¯å¢ƒ: {eval_task.env_config['task']}")
        print(f"  å‰§é›†æ•°: {eval_task.eval_config['n_episodes']}")
        print(f"  æ¸²æŸ“å‰§é›†æ•°: {eval_task.max_episodes_rendered}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°ä»»åŠ¡æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def display_video_info(video_outputs_dir: Path):
    """æ˜¾ç¤ºç”Ÿæˆçš„è§†é¢‘ä¿¡æ¯"""
    print(f"\nğŸ“¹ ç”Ÿæˆçš„è¯„ä¼°è§†é¢‘:")
    print(f"è§†é¢‘ä¿å­˜ä½ç½®: {video_outputs_dir}")
    
    video_files = list(video_outputs_dir.glob("*.mp4"))
    if video_files:
        print(f"ğŸ“Š è§†é¢‘ç»Ÿè®¡:")
        print(f"  æ€»è§†é¢‘æ•°é‡: {len(video_files)}")
        
        total_size = 0
        for video_file in video_files:
            file_size = video_file.stat().st_size
            total_size += file_size
            size_mb = file_size / (1024 * 1024)
            print(f"  ğŸ“„ {video_file.name} ({size_mb:.2f} MB)")
        
        total_size_mb = total_size / (1024 * 1024)
        print(f"  ğŸ“Š æ€»å¤§å°: {total_size_mb:.2f} MB")
        
        print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print(f"  å¯ä»¥ä½¿ç”¨è§†é¢‘æ’­æ”¾å™¨æ‰“å¼€è¿™äº›æ–‡ä»¶è§‚çœ‹è¯„ä¼°è¿‡ç¨‹")
        print(f"  æ–‡ä»¶è·¯å¾„: {video_outputs_dir.absolute()}")
        
    else:
        print("âš ï¸  æœªæ‰¾åˆ°ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶")

async def run_video_evaluation_test():
    """è¿è¡Œè§†é¢‘è¯„ä¼°æµ‹è¯•"""
    print("ğŸ¬ å¼€å§‹è¯„ä¼°è§†é¢‘ç”Ÿæˆæµ‹è¯•")
    print("=" * 60)
    
    outputs_dir, video_dir, results_dir = setup_video_environment()
    
    tests = [
        ("è¯„ä¼°ä»»åŠ¡æ¨¡å‹", test_task_model),
        ("ç›´æ¥è¯„ä¼°è°ƒç”¨ï¼ˆç”Ÿæˆè§†é¢‘ï¼‰", test_direct_evaluation_with_videos),
    ]
    
    passed = 0
    total = len(tests)
    all_videos = []
    all_results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
                if isinstance(result, tuple):
                    success, videos, results = result
                    if success:
                        passed += 1
                        all_videos.extend(videos)
                        all_results.update(results)
                    result = success
                else:
                    if result:
                        passed += 1
            else:
                result = test_func()
                if result:
                    passed += 1
                
            if result:
                print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
    
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    print(f"{'='*60}")
    
    # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
    display_video_info(video_dir)
    
    if passed >= 1:  # è‡³å°‘æœ‰ä¸€ä¸ªæµ‹è¯•é€šè¿‡
        print("\nğŸ‰ è§†é¢‘è¯„ä¼°æµ‹è¯•å®Œæˆï¼")
        print("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
        if len(all_videos) > 0:
            print(f"âœ… æˆåŠŸç”Ÿæˆ {len(all_videos)} ä¸ªè¯„ä¼°è§†é¢‘")
            print(f"âœ… è§†é¢‘ä¿å­˜åœ¨: {video_dir}")
            print(f"âœ… ç»“æœä¿å­˜åœ¨: {results_dir}")
        
        print("\nğŸ¯ ç”Ÿæˆçš„å†…å®¹:")
        print("â€¢ è¯„ä¼°è¿‡ç¨‹è§†é¢‘æ–‡ä»¶ (.mp4)")
        print("â€¢ è¯„ä¼°ç»“æœæ•°æ® (.json)")
        print("â€¢ è¯¦ç»†çš„å‰§é›†ç»Ÿè®¡ä¿¡æ¯")
        
        print(f"\nğŸ“ è¾“å‡ºç›®å½•ç»“æ„:")
        print(f"outputs/")
        print(f"â”œâ”€â”€ evaluation_videos/  # è¯„ä¼°è§†é¢‘æ–‡ä»¶")
        print(f"â””â”€â”€ evaluation_results/ # è¯„ä¼°ç»“æœæ•°æ®")
        
    else:
        print("âš ï¸  è§†é¢‘è¯„ä¼°æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
        print("\nğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œç¡®ä¿èƒ½è®¿é—® Hugging Face Hub")
        print("2. ç¡®ä¿ LeRobot ç¯å¢ƒæ­£ç¡®å®‰è£…")
        print("3. éªŒè¯è¯„ä¼°ç¯å¢ƒé…ç½®")
    
    return passed >= 1

def main():
    """ä¸»å‡½æ•°"""
    try:
        success = asyncio.run(run_video_evaluation_test())
        
        if success:
            print("\nğŸŠ è¯„ä¼°è§†é¢‘ç”Ÿæˆæµ‹è¯•å®Œæˆï¼")
            print("ğŸ¬ å¯ä»¥åœ¨ outputs/evaluation_videos/ ç›®å½•ä¸­æŸ¥çœ‹ç”Ÿæˆçš„è§†é¢‘ã€‚")
        else:
            print("\nâŒ è¯„ä¼°è§†é¢‘ç”Ÿæˆæµ‹è¯•å¤±è´¥ã€‚")
        
        return 0 if success else 1
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿è¡Œå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 