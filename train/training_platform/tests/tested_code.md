ç°åœ¨æˆ‘åœ¨åšä¸€ä¸ªè®­ç»ƒæœåŠ¡å¹³å°ï¼Œè¦è´Ÿè´£è®­ç»ƒå™¨çš„éƒ¨åˆ†ã€‚å¤§æ¦‚åˆ†ä¸ºä¸‰ä¸ªå¤§ç±»ã€‚ä¸€ä¸ªæ˜¯schedulerç±»ï¼Œè´Ÿè´£æ¥å—åç«¯çš„ä»»åŠ¡è¯·æ±‚ã€‚åç«¯é€šè¿‡RabbitMQå‘é€ä¸€ä¸ªæ–°çš„ä»»åŠ¡ç»™schedulerï¼ŒåŒ…æ‹¬taskid,userid,config,uuidç­‰ä¸€ç³»åˆ—å†…å®¹ã€‚schedulerä¸»è¦ç»´æŠ¤ä¸€ä¸ªä»»åŠ¡é˜Ÿåˆ—ï¼Œé€šè¿‡FIFOçš„æ–¹å¼ç»´æŠ¤é‡Œé¢çš„è®­ç»ƒä»»åŠ¡ï¼Œè®°å½•æ¯ä¸ªä»»åŠ¡è®­ç»ƒçš„å¤šå°‘æ­¥ã€‚åˆ°è¾¾ä¸€å®šstepä¹‹ååˆ‡æ¢ä¸‹ä¸€ä¸ªä»»åŠ¡å¹¶æ‰”åˆ°é˜Ÿå°¾ã€‚å½“é˜Ÿåˆ—çŠ¶æ€æ”¹å˜ï¼šAä»»åŠ¡å¼€å§‹è®­ç»ƒ/ Aä»»åŠ¡è¢«åˆ é™¤/ Aä»»åŠ¡åœ¨æ’é˜Ÿè®­ç»ƒã€‚éƒ½éœ€è¦ç”¨RabbitMQå‘ç»™åç«¯è¿›è¡ŒçŠ¶æ€ä¿®æ”¹ã€‚æ¥ä¸‹æ¥scheduleré€‰ä¸­çš„ä»»åŠ¡ä¼šè¿›å…¥Trainer è¿›è¡Œè®­ç»ƒã€‚å¯ä»¥ä½¿ç”¨ç±»ä¼¼rayçš„æ¡†æ¶ï¼Œæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒï¼Œä¸»è¦ä½¿ç”¨ray Trainä»¥ä¾¿äºéƒ¨ç½²åˆ°å¤šå¡ä¸Šã€‚trainerçš„ä»£ç ä¸»è¦å‚è€ƒlerobotä¸­trainçš„ä»£ç ï¼Œä¼šä¾èµ–lerobotä¸­å¾ˆå¤šåº“çš„å†…å®¹ã€‚åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼ŒLoggerè´Ÿè´£å®æ—¶å°†è®­ç»ƒè¿›å±•ï¼ˆå½“å‰stepï¼Œlossç­‰ï¼‰é€šè¿‡rabbitMQå‘é€ç»™åç«¯ï¼Œä»¥ä¾¿äºå‰ç«¯é¡µé¢çš„å®æ—¶æ›´æ–°ã€‚æœ€åè®­ç»ƒç»“æŸåï¼Œæˆ–è€…é—´éš”ä¸€æ®µæ—¶é—´ï¼Œä¼šæŠŠckptæ”¾åœ¨minIOå­˜å‚¨ä¸­ã€‚æˆ‘ç°åœ¨å·²ç»å†™äº†trainActorå’Œtrainlogicçš„åŸºæœ¬å®ç°ï¼Œç°åœ¨è¦æµ‹è¯•ä¸€ä¸‹TrainActorçš„åŸºæœ¬åŠŸèƒ½ï¼ˆåœ¨rayç¯å¢ƒä¸­ï¼‰ã€‚æš‚æ—¶ä¸ä¼šæµ‹è¯•schedulerçš„å®ç°ã€‚ä½†æ˜¯æˆ‘ä¼šæŠŠschedulerçš„è°ƒç”¨ç»™ä½ ã€‚æµ‹è¯•å¤§æ¦‚åˆ†ä¸ºè¿™ä¹ˆå‡ ä¸ªéƒ¨åˆ†ã€‚æµ‹è¯•ä¸€ï¼šé¢„å…ˆåœ¨minioä¸­å­˜å‚¨ä¸€ä¸ªdatasetï¼Œactorä»ä¸­å¾—åˆ°æ•°æ®é›†ä¹‹åå¼€å§‹è®­ç»ƒï¼Œç„¶åå†minioä¸­save ckptã€‚ æµ‹è¯•äºŒï¼šæ£€æµ‹æ˜¯å¦èƒ½ä»ä¸­æ–­ç‚¹ç»§ç»­è¿›è¡Œè®­ç»ƒã€‚ï¼ˆæœ¬é˜¶æ®µä¸åšè¦æ±‚ï¼‰ã€‚æ•°æ®é›†çš„ä¸‹è½½ä½¿ç”¨huggingface lerobotï¼Œå­˜å‚¨åˆ°minioä¸­ä½œä¸ºåˆå§‹datasetï¼ˆæµ‹è¯•é¢„å¤„ç†ï¼‰å…·ä½“è·¯å¾„åœ¨æ¥ä¸‹æ¥æˆ‘ç»™ä½ çš„configä¸­æœ‰ä½“ç°ã€‚trainActoræ¥å—ä¸€ä¸ªTrainingTaskä½œä¸ºè¾“å…¥ï¼Œä½ å¯ä»¥è¿›è¡Œä¸€äº›è‡ªå®šä¹‰ï¼Œä½†æ˜¯å…·ä½“å­—æ®µéœ€è¦è´Ÿè´£æˆ‘ç»™ä½ çš„è¿™ä¸ªconfigã€‚è¿™ä¸ªconfigçš„è·¯å¾„åœ¨./config/act_aloha_config.json
{
"dataset": {
"repo_id": "lerobot/aloha_sim_insertion_human",
"episodes": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
"video_backend": "pyav",
"image_transforms": {
"enable": true
}
},
"env": {
"type": "aloha",
"task": "AlohaInsertion-v0",
"fps": 50,
"episode_length": 400,
"obs_type": "pixels_agent_pos",
"render_mode": "rgb_array"
},
"policy": {
"type": "act",
"device": "cuda",
"use_amp": true,
"n_obs_steps": 1,
"chunk_size": 100,
"n_action_steps": 100,
"vision_backbone": "resnet18",
"pretrained_backbone_weights": "ResNet18_Weights.IMAGENET1K_V1",
"replace_final_stride_with_dilation": false,
"pre_norm": false,
"dim_model": 512,
"n_heads": 8,
"dim_feedforward": 3200,
"feedforward_activation": "relu",
"n_encoder_layers": 4,
"n_decoder_layers": 1,
"use_vae": true,
"latent_dim": 32,
"n_vae_encoder_layers": 4,
"temporal_ensemble_coeff": null,
"dropout": 0.1,
"kl_weight": 10.0,
"optimizer_lr": 1e-5,
"optimizer_weight_decay": 1e-4,
"optimizer_lr_backbone": 1e-5
},
"output_dir": null,
"job_name": null,
"resume": false,
"seed": 1000,
"num_gpus": 1,
"num_workers": 4,
"batch_size": 8,
"steps": 100000,
"eval_freq": 20000,
"log_freq": 200,
"save_checkpoint": true,
"save_freq": 20000,
"use_policy_training_preset": true,
"optimizer": null,
"scheduler": null,
"eval": {
"n_episodes": 10,
"batch_size": 4
},
"wandb": {
"enable": false,
"disable_artifact": false,
"project": "lerobot",
"entity": null,
"notes": null,
"run_id": null
}
}

ä»¥ä¸‹æ˜¯ä¸€äº›ä½ å¯èƒ½éœ€è¦çš„æ–‡ä»¶ï¼Œåœ¨ä»¥ä¸‹training platformç›®å½•é‡Œå¯ä»¥æ‰¾åˆ°
.
â”œâ”€â”€ init.py
â”œâ”€â”€ pycache
â”‚   â””â”€â”€ init.cpython-310.pyc
â”œâ”€â”€ common
â”‚   â”œâ”€â”€ init.py
â”‚   â”œâ”€â”€ pycache
â”‚   â”‚   â”œâ”€â”€ init.cpython-310.pyc
â”‚   â”‚   â”œâ”€â”€ minio_utils.cpython-310.pyc
â”‚   â”‚   â”œâ”€â”€ rabbitmq_utils.cpython-310.pyc
â”‚   â”‚   â””â”€â”€ task_models.cpython-310.pyc
â”‚   â”œâ”€â”€ minio_utils.py
â”‚   â”œâ”€â”€ rabbitmq_utils.py
â”‚   â””â”€â”€ task_models.py
â”œâ”€â”€ configs
â”‚   â”œâ”€â”€ pycache
â”‚   â”‚   â””â”€â”€ settings.cpython-310.pyc
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scheduler
â”‚   â”œâ”€â”€ init.py
â”‚   â”œâ”€â”€ pycache
â”‚   â”‚   â”œâ”€â”€ init.cpython-310.pyc
â”‚   â”‚   â””â”€â”€ scheduler_actor.cpython-310.pyc
â”‚   â””â”€â”€ scheduler_actor.py
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ init.py
â”‚   â”œâ”€â”€ pycache
â”‚   â”‚   â”œâ”€â”€ init.cpython-310.pyc
â”‚   â”‚   â”œâ”€â”€ minio_data_prepare.cpython-310.pyc
â”‚   â”‚   â”œâ”€â”€ state_fixture.cpython-310.pyc
â”‚   â”‚   â”œâ”€â”€ test_config_loading.cpython-310.pyc
â”‚   â”‚   â”œâ”€â”€ test_pipeline.cpython-310-pytest-8.4.1.pyc
â”‚   â”‚   â””â”€â”€ test_pipeline.cpython-310.pyc
â”‚   â”œâ”€â”€ full_integration_test.py
â”‚   â”œâ”€â”€ minio_data_prepare.py
â”‚   â”œâ”€â”€ state_fixture.py
â”‚   â”œâ”€â”€ test_config_loading.py
â”‚   â”œâ”€â”€ test_logic_modules.py
â”‚   â””â”€â”€ test_pipeline.py
â””â”€â”€ trainer
â”œâ”€â”€ init.py
â”œâ”€â”€ pycache
â”‚   â”œâ”€â”€ init.cpython-310.pyc
â”‚   â”œâ”€â”€ lerobot_trainer_logic.cpython-310.pyc
â”‚   â””â”€â”€ trainer_actor.cpython-310.pyc
â”œâ”€â”€ lerobot_train_actor.py
â”œâ”€â”€ lerobot_trainer_logic.py
â””â”€â”€ trainer_actor.py
é¡¹ç›®å®Œæ•´ç»“æ„å¦‚ä¸‹
.
â”œâ”€â”€ benchmarks
â”‚   â””â”€â”€ video
â”œâ”€â”€ config
â”œâ”€â”€ docker
â”‚   â”œâ”€â”€ lerobot-cpu
â”‚   â”œâ”€â”€ lerobot-gpu
â”‚   â””â”€â”€ lerobot-gpu-dev
â”œâ”€â”€ examples
â”‚   â”œâ”€â”€ advanced
â”‚   â””â”€â”€ port_datasets
â”œâ”€â”€ lerobot
â”‚   â”œâ”€â”€ pycache
â”‚   â”œâ”€â”€ common
â”‚   â”‚   â”œâ”€â”€ pycache
â”‚   â”‚   â”œâ”€â”€ datasets
â”‚   â”‚   â”‚   â”œâ”€â”€ pycache
â”‚   â”‚   â”‚   â”œâ”€â”€ push_dataset_to_hub
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ aloha_raw_urls
â”‚   â”‚   â”‚   â”œâ”€â”€ v2
â”‚   â”‚   â”‚   â””â”€â”€ v21
â”‚   â”‚   â”œâ”€â”€ envs
â”‚   â”‚   â”‚   â””â”€â”€ pycache
â”‚   â”‚   â”œâ”€â”€ optim
â”‚   â”‚   â”‚   â””â”€â”€ pycache
â”‚   â”‚   â”œâ”€â”€ policies
â”‚   â”‚   â”‚   â”œâ”€â”€ pycache
â”‚   â”‚   â”‚   â”œâ”€â”€ act
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ pycache
â”‚   â”‚   â”‚   â”œâ”€â”€ diffusion
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ pycache
â”‚   â”‚   â”‚   â”œâ”€â”€ pi0
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pycache
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ conversion_scripts
â”‚   â”‚   â”‚   â”œâ”€â”€ tdmpc
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ pycache
â”‚   â”‚   â”‚   â””â”€â”€ vqbet
â”‚   â”‚   â”‚       â””â”€â”€ pycache
â”‚   â”‚   â”œâ”€â”€ robot_devices
â”‚   â”‚   â”‚   â”œâ”€â”€ cameras
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ pycache
â”‚   â”‚   â”‚   â”œâ”€â”€ motors
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ pycache
â”‚   â”‚   â”‚   â””â”€â”€ robots
â”‚   â”‚   â”‚       â””â”€â”€ pycache
â”‚   â”‚   â””â”€â”€ utils
â”‚   â”‚       â””â”€â”€ pycache
â”‚   â”œâ”€â”€ configs
â”‚   â”‚   â””â”€â”€ pycache
â”‚   â”œâ”€â”€ scripts
â”‚   â”‚   â””â”€â”€ pycache
â”‚   â””â”€â”€ templates
â”œâ”€â”€ media
â”‚   â”œâ”€â”€ aloha
â”‚   â”œâ”€â”€ gym
â”‚   â”œâ”€â”€ koch
â”‚   â”œâ”€â”€ lekiwi
â”‚   â”œâ”€â”€ moss
â”‚   â”œâ”€â”€ so100
â”‚   â””â”€â”€ tutorial
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ pycache
â”‚   â”œâ”€â”€ artifacts
â”‚   â”‚   â”œâ”€â”€ datasets
â”‚   â”‚   â”‚   â””â”€â”€ lerobot
â”‚   â”‚   â”‚       â”œâ”€â”€ aloha_sim_insertion_human
â”‚   â”‚   â”‚       â”œâ”€â”€ pusht
â”‚   â”‚   â”‚       â””â”€â”€ xarm_lift_medium
â”‚   â”‚   â”œâ”€â”€ image_transforms
â”‚   â”‚   â””â”€â”€ policies
â”‚   â”‚       â”œâ”€â”€ aloha_sim_insertion_human_act
â”‚   â”‚       â”œâ”€â”€ aloha_sim_insertion_human_act_1000_steps
â”‚   â”‚       â”œâ”€â”€ pusht_diffusion_
â”‚   â”‚       â”œâ”€â”€ xarm_lift_medium_tdmpc_use_mpc
â”‚   â”‚       â””â”€â”€ xarm_lift_medium_tdmpc_use_policy
â”‚   â”œâ”€â”€ cameras
â”‚   â”œâ”€â”€ configs
â”‚   â”œâ”€â”€ datasets
â”‚   â”œâ”€â”€ envs
â”‚   â”œâ”€â”€ examples
â”‚   â”œâ”€â”€ fixtures
â”‚   â”‚   â””â”€â”€ pycache
â”‚   â”œâ”€â”€ motors
â”‚   â”œâ”€â”€ optim
â”‚   â”œâ”€â”€ policies
â”‚   â”œâ”€â”€ robots
â”‚   â””â”€â”€ utils
â”œâ”€â”€ tmp_test_config_dir
â”œâ”€â”€ tmp_test_runs
â””â”€â”€ training_platform
â”œâ”€â”€ pycache
â”œâ”€â”€ common
â”‚   â””â”€â”€ pycache
â”œâ”€â”€ configs
â”‚   â””â”€â”€ pycache
â”œâ”€â”€ scheduler
â”‚   â””â”€â”€ pycache
â”œâ”€â”€ tests
â”‚   â””â”€â”€ pycache
â””â”€â”€ trainer
â””â”€â”€ pycache

ä½ éœ€è¦çš„æ–‡ä»¶å¦‚ä¸‹

import ray
import asyncio
from collections import deque
from typing import Deque, Optional

from training_platform.configs.settings import settings
from training_platform.common.task_models import TrainingTask
from training_platform.common.rabbitmq_utils import init_rabbitmq, send_status_message
from training_platform.trainer.trainer_actor import TrainerActor

@ray.remote
class Scheduler:
def init(self):
self.task_queue: Deque[TrainingTask] = deque()
self.running_task: Optional[TrainingTask] = None
self.trainer_actor: Optional["ray.actor.ActorHandle"] = None

Generated code
self.steps_per_timeslice = settings.SCHEDULER_STEPS_PER_TIMESLICE
    self.num_gpus_per_trainer = settings.SCHEDULER_GPUS_PER_TRAINER
    
    # Actor å¯åŠ¨æ—¶ï¼Œè°ƒç”¨ä¸€æ¬¡ init_rabbitmq æ¥ç¡®ä¿è¿æ¥
    # Manager æ¨¡å¼ä¼šå¤„ç†é‡å¤è°ƒç”¨çš„é—®é¢˜
    asyncio.create_task(init_rabbitmq())
    
    print("[Scheduler] Actor initialized.")

async def add_task(self, task_data: dict):
    task = TrainingTask(**task_data)
    self.task_queue.append(task)
    await send_status_message(task_id=int(task.task_id), status="queued", uuid=task.uuid)
    print(f"[Scheduler] Task {task.task_id} added to queue.")

async def run(self):
    print("[Scheduler] Main loop started.")
    while True:
        if self.running_task is None and self.task_queue:
            self.running_task = self.task_queue.popleft()
            
            print(f"[Scheduler] Starting training for task: {self.running_task.task_id}")
            
            trainer_options = {"num_gpus": self.num_gpus_per_trainer}
            self.trainer_actor = TrainerActor.options(**trainer_options).remote(self.running_task)
            
            total_epochs = self.running_task.config.get('epochs', 10)
            start_epoch = self.running_task.current_step
            end_epoch = min(start_epoch + self.steps_per_timeslice, total_epochs)
            
            await send_status_message(task_id=int(self.running_task.task_id), status="training", uuid=self.running_task.uuid)
            
            try:
                final_epoch = await self.trainer_actor.train.remote(start_epoch, end_epoch)
                self.running_task.current_step = final_epoch
                
                if final_epoch >= total_epochs:
                    await send_status_message(task_id=int(self.running_task.task_id), status="completed", uuid=self.running_task.uuid)
                else:
                    self.task_queue.append(self.running_task)
                    await send_status_message(task_id=int(self.running_task.task_id), status="paused", uuid=self.running_task.uuid)
            except Exception as e:
                print(f"âŒ [Scheduler] Training failed for task {self.running_task.task_id}: {e}")
                await send_status_message(task_id=int(self.running_task.task_id), status="failed", uuid=self.running_task.uuid)
            finally:
                if self.trainer_actor: ray.kill(self.trainer_actor)
                self.trainer_actor, self.running_task = None, None
        
        await asyncio.sleep(1)

Pydantic models for task definitions # common/task_models.py

from pydantic import BaseModel, Field
from typing import Dict, Any, Optional

class TrainingTask(BaseModel):
task_id: str
user_id: str
uuid: str
config: Dict[str, Any]  # å¯¹åº” lerobot çš„ TrainPipelineConfig å†…å®¹

Generated code
# ç”± Scheduler ç»´æŠ¤çš„çŠ¶æ€
current_step: int = 0
status: str = "queued" # queued, training, paused, completed, failed
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END

import os
import mimetypes
import asyncio
from typing import Optional, Tuple
from miniopy_async.api import Minio
from miniopy_async.error import S3Error

å¯¼å…¥ settings

from training_platform.configs.settings import settings

class _MinIOManager:
_instance: Optional['_MinIOManager'] = None
_lock = asyncio.Lock()

Generated code
def __init__(self):
    self.client: Optional[Minio] = None
    self._is_connecting = False

@classmethod
async def get_instance(cls) -> '_MinIOManager':
    # (è¿™ä¸ªæ–¹æ³•ä¿æŒä¸å˜)
    if cls._instance is None:
        async with cls._lock:
            if cls._instance is None:
                cls._instance = cls()
    return cls._instance

async def get_client_internal(self) -> Minio:
    # æ£€æŸ¥è¿æ¥æ˜¯å¦å·²å…³é—­æˆ–ä¸å­˜åœ¨
    client_is_invalid = self.client is None
    if self.client and hasattr(self.client, '_http') and self.client._http:
         client_is_invalid = self.client._http.is_closed()
    
    if client_is_invalid:
        async with self._lock:
            # å†æ¬¡æ£€æŸ¥ï¼Œé˜²æ­¢åœ¨ç­‰å¾…é”æ—¶è¿æ¥å·²è¢«å…¶ä»–åç¨‹å»ºç«‹
            client_is_invalid_again = self.client is None
            if self.client and hasattr(self.client, '_http') and self.client._http:
                client_is_invalid_again = self.client._http.is_closed()
            
            if client_is_invalid_again:
                if self._is_connecting:
                    while self._is_connecting:
                        await asyncio.sleep(0.1)
                    # åœ¨ç­‰å¾…åï¼Œå¦ä¸€ä¸ªåç¨‹å¯èƒ½å·²ç»æˆåŠŸè¿æ¥ï¼Œç›´æ¥è¿”å›
                    if self.client and not self.client._http.is_closed():
                        return self.client
                    else:
                        # å¦‚æœç­‰å¾…åä»ç„¶è¿æ¥å¤±è´¥ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
                        raise ConnectionError("å¦ä¸€ä¸ªåç¨‹å°è¯•è¿æ¥å¤±è´¥ã€‚")

                self._is_connecting = True
                try:
                    print(f"ğŸ’¡ æ­£åœ¨è¿æ¥åˆ° MinIO æœåŠ¡å™¨: {settings.MINIO_URL} ...")
                    client = Minio(
                        endpoint=settings.MINIO_URL,
                        access_key=settings.MINIO_ACCESS_KEY,
                        secret_key=settings.MINIO_SECRET_KEY,
                        secure=False
                    )
                    # ä½¿ç”¨ä¸€ä¸ªè½»é‡çº§çš„æ“ä½œä½œä¸ºå¥åº·æ£€æŸ¥
                    await client.bucket_exists("health-check-bucket-that-may-not-exist")
                    self.client = client
                    print("âœ… æˆåŠŸè¿æ¥åˆ° MinIO æœåŠ¡å™¨ï¼")
                except Exception as e:
                    print(f"âŒ è¿æ¥ MinIO å¤±è´¥ã€‚åŸå§‹é”™è¯¯: {e}")
                    self.client = None
                    # --- å…³é”®ä¿®æ”¹ï¼šç›´æ¥æŠ›å‡ºå¼‚å¸¸ ---
                    raise ConnectionError(f"æ— æ³•è¿æ¥åˆ° MinIO æœåŠ¡å™¨ at {settings.MINIO_URL}") from e
                finally:
                    self._is_connecting = False
    
    # èƒ½èµ°åˆ°è¿™é‡Œï¼Œself.client ä¸€å®šæ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„å¯¹è±¡
    return self.client
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END
--- å‡½æ•°æ¥å£ ---
--- å…³é”®ä¿®æ”¹ï¼šè®©å‡½æ•°åœ¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œä¸æ˜¯è¿”å› None ---

async def get_minio_client() -> Minio:
"""
è·å–ä¸€ä¸ªä¿è¯å¯ç”¨çš„ MinIO å®¢æˆ·ç«¯ã€‚å¦‚æœæ— æ³•è¿æ¥ï¼Œåˆ™æŠ›å‡º ConnectionErrorã€‚
"""
manager = await _MinIOManager.get_instance()
return await manager.get_client_internal()

async def connect_minio() -> Minio:
"""
è¿æ¥åˆ° MinIOã€‚è¿™æ˜¯ get_minio_client çš„åˆ«åã€‚
"""
return await get_minio_client()

å…¶ä»–å‡½æ•°ä¿æŒå®Œå…¨ä¸å˜ï¼Œå› ä¸ºå®ƒä»¬ä¾èµ–ä¼ å…¥çš„ client å¯¹è±¡

async def upload_model_to_minio(
client: Minio,
dataset_file_local_path: str,
filename: str,
) -> Tuple[bool, str]:
from training_platform.configs.settings import settings # åœ¨å‡½æ•°å†…å¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
return await upload_file_to_minio(
client=client,
upload_file_local_path=dataset_file_local_path,
filename=filename,
bucket_name=settings.MINIO_MODEL_BUCKET,
object_prefix="models/"
)

async def download_file_from_minio(
client: Minio,
bucket_name: str,
object_name: str,
local_file_path: str
) -> Tuple[bool, str]:
if not isinstance(client, Minio):
return False, "ä¼ å…¥çš„ MinIO å®¢æˆ·ç«¯æ— æ•ˆæˆ–æœªåˆå§‹åŒ–ã€‚"
try:
found = await client.bucket_exists(bucket_name)
if not found:
return False, f"æ¡¶ '{bucket_name}' ä¸å­˜åœ¨ã€‚"
await client.fget_object(bucket_name, object_name, local_file_path)
print(f"â¬‡ï¸ æ–‡ä»¶ '{object_name}' å·²æˆåŠŸä¸‹è½½åˆ° '{local_file_path}'ã€‚")
return True, local_file_path
except S3Error as e:
error_msg = f"MinIO ä¸‹è½½å¤±è´¥: {e}"
print(f"âŒ {error_msg}")
return False, error_msg
except Exception as e:
error_msg = f"æ–‡ä»¶ä¸‹è½½æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"
print(f"âŒ {error_msg}")
return False, error_msg

async def upload_file_to_minio(
client: Minio,
upload_file_local_path: str,
filename: str,
bucket_name: str,
object_prefix: str = "",
) -> Tuple[bool, str]:
if not isinstance(client, Minio):
return False, "ä¼ å…¥çš„ MinIO å®¢æˆ·ç«¯æ— æ•ˆæˆ–æœªåˆå§‹åŒ–ã€‚"
try:
found = await client.bucket_exists(bucket_name)
if not found:
await client.make_bucket(bucket_name)
print(f"Bucket '{bucket_name}' ä¸å­˜åœ¨ï¼Œå·²è‡ªåŠ¨åˆ›å»ºã€‚")

Generated code
object_name = f"{object_prefix}{filename}"
    content_type, _ = mimetypes.guess_type(upload_file_local_path)
    content_type = content_type or 'application/octet-stream'

    await client.fput_object(bucket_name, object_name, upload_file_local_path, content_type=content_type)
    print(f"âœ… æ–‡ä»¶ '{upload_file_local_path}' å·²æˆåŠŸä¸Šä¼ åˆ° '{bucket_name}/{object_name}'ã€‚")
    return True, f"s3://{bucket_name}/{object_name}"
except S3Error as e:
    error_msg = f"MinIO ä¸Šä¼ å¤±è´¥: {e}"
    print(f"âŒ {error_msg}")
    return False, error_msg
except Exception as e:
    error_msg = f"æ–‡ä»¶ä¸Šä¼ æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"
    print(f"âŒ {error_msg}")
    return False, error_msg
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END

import asyncio
import json
from typing import Optional, Callable
import aio_pika
from aio_pika.abc import AbstractRobustConnection, AbstractChannel, AbstractExchange, AbstractQueue

from training_platform.configs.settings import settings

class _RabbitMQManager:
"""
ä¸€ä¸ªå†…éƒ¨å•ä¾‹ç±»ï¼Œç”¨äºç®¡ç† RabbitMQ è¿æ¥çš„ç”Ÿå‘½å‘¨æœŸã€‚
å¯¹å¤–éƒ¨è°ƒç”¨è€…é€æ˜ã€‚
"""
_instance: Optional['_RabbitMQManager'] = None
_lock = asyncio.Lock()

Generated code
def __init__(self):
    self.connection: Optional[AbstractRobustConnection] = None
    self.channel: Optional[AbstractChannel] = None
    self.exchange: Optional[AbstractExchange] = None
    self.queues: dict[str, AbstractQueue] = {}

@classmethod
async def get_instance(cls) -> '_RabbitMQManager':
    if cls._instance is None:
        async with cls._lock:
            if cls._instance is None:
                cls._instance = cls()
    return cls._instance

async def initialize_internal(self):
    if self.channel and not self.channel.is_closed:
        return

    async with self._lock:
        if self.channel and not self.channel.is_closed:
            return

        try:
            print(f"ğŸ’¡ æ­£åœ¨è¿æ¥ RabbitMQ å¹¶å£°æ˜æ‰€æœ‰å®ä½“...")
            self.connection = await aio_pika.connect_robust(settings.RABBITMQ_URL)
            self.channel = await self.connection.channel()
            self.exchange = await self.channel.declare_exchange(
                settings.RABBIT_EXCHANGE_NAME, aio_pika.ExchangeType.DIRECT, durable=True
            )
            self.fanout_exchange = await self.channel.declare_exchange(
                "platform.fanout.status", # ä¸€ä¸ªæ–°çš„ã€ä¸“é—¨ç”¨äºæµ‹è¯•å¹¿æ’­çš„äº¤æ¢æœº
                aio_pika.ExchangeType.FANOUT,
                durable=True
            )

            queue_configs = {
                settings.RABBIT_REQUEST_QUEUE_NAME: settings.RABBIT_REQUEST_BINDING_KEY,
                settings.RABBIT_STATUS_QUEUE_NAME: settings.RABBIT_STATUS_BINDING_KEY,
                settings.RABBIT_TRAIN_LOG_QUEUE_NAME: settings.RABBIT_TRAIN_LOG_BINDING_KEY,
            }
            for q_name, r_key in queue_configs.items():
                queue = await self.channel.declare_queue(q_name, durable=True)
                await queue.bind(self.exchange, routing_key=r_key)
                self.queues[q_name] = queue

            print("âœ… RabbitMQ åˆå§‹åŒ–æˆåŠŸï¼")
        except Exception as e:
            print(f"âŒ RabbitMQ åˆå§‹åŒ–å¤±è´¥: {e}")
            if self.connection: await self.connection.close()
            self.connection = self.channel = self.exchange = None; self.queues = {}
            raise

async def close_internal(self):
    if self.connection and not self.connection.is_closed:
        await self.connection.close()
        self.connection = None
        print("ğŸ‘‹ RabbitMQ è¿æ¥å·²å…³é—­ã€‚")
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END
--- ä»¥ä¸‹æ˜¯ä½ åŸæœ‰çš„å‡½æ•°ï¼Œæˆ‘ä»¬ä¿æŒæ¥å£ä¸å˜ï¼Œä½†å†…éƒ¨å®ç°è°ƒç”¨Manager ---

async def init_rabbitmq():
manager = await _RabbitMQManager.get_instance()
await manager.initialize_internal()

async def close_rabbitmq():
manager = await _RabbitMQManager.get_instance()
await manager.close_internal()

async def get_rabbit_exchange() -> Optional[AbstractExchange]:
manager = await _RabbitMQManager.get_instance()
await manager.initialize_internal() # ç¡®ä¿å·²åˆå§‹åŒ–
return manager.exchange

async def _send_message(routing_key: str, message_body: dict):
try:
exchange = await get_rabbit_exchange()
if not exchange:
print(f"å‘é€æ¶ˆæ¯å¤±è´¥: äº¤æ¢æœºæœªå°±ç»ªã€‚")
return
message = aio_pika.Message(
body=json.dumps(message_body).encode('utf-8'),
delivery_mode=aio_pika.DeliveryMode.PERSISTENT
)
await exchange.publish(message, routing_key=routing_key)
except Exception as e:
print(f"å‘é€æ¶ˆæ¯åˆ° {routing_key} å¤±è´¥: {e}")

async def send_status_message(task_id: int, status: str, uuid: Optional[str] = None):
manager = await _RabbitMQManager.get_instance()
await manager.initialize_internal()
message_body = {"task_id": task_id, "status": status, "model_uuid": uuid}
if manager.fanout_exchange and manager.fanout_exchange.name == "platform.fanout.status":
try:
message = aio_pika.Message(
body=json.dumps(message_body).encode('utf-8')
# fanout exchange çš„æ¶ˆæ¯ä¸éœ€è¦æŒä¹…åŒ–
)
# å‘é€åˆ° fanout exchange, routing_key ä¸ºç©º
await manager.fanout_exchange.publish(message, routing_key="")
except Exception as e:
print(f"å¹¿æ’­çŠ¶æ€æ¶ˆæ¯å¤±è´¥: {e}")

async def send_log_message(epoch: int, loss: float, accuracy: float, log_message: str):
message_body = {"epoch": epoch, "loss": loss, "accuracy": accuracy, "log_message": log_message}
await _send_message(settings.RABBIT_TRAIN_LOG_BINDING_KEY, message_body)

async def start_task_queue_consumer(on_message_callback: Callable):
try:
manager = await _RabbitMQManager.get_instance()
await manager.initialize_internal() # ç¡®ä¿å·²åˆå§‹åŒ–
queue = manager.queues.get(settings.RABBIT_REQUEST_QUEUE_NAME)
if not queue:
print(f"âŒ æ— æ³•å¯åŠ¨æ¶ˆè´¹è€…ï¼šé˜Ÿåˆ— '{settings.RABBIT_REQUEST_QUEUE_NAME}' æœªæ‰¾åˆ°ã€‚")
return
print(f"[*] å¼€å§‹ç›‘å¬é˜Ÿåˆ— '{queue.name}'.")
await queue.consume(on_message_callback, no_ack=False)
except Exception as e:
print(f"âŒ å¯åŠ¨æ¶ˆè´¹è€…å¤±è´¥: {e}")

training_platform/trainer/lerobot_trainer_logic.py (æ¨¡å—åŒ–ç‰ˆæœ¬)

import logging
from pathlib import Path
from pprint import pformat
from typing import Callable, Dict, Any, Tuple

import torch
from torch.amp import GradScaler
import draccus

å¯¼å…¥æ‰€æœ‰ lerobot çš„ä¾èµ–

from lerobot.common.datasets.factory import make_dataset
from lerobot.common.datasets.sampler import EpisodeAwareSampler
from lerobot.common.datasets.utils import cycle
from lerobot.common.policies.factory import make_policy
from lerobot.common.optim.factory import make_optimizer_and_scheduler
from lerobot.common.utils.logging_utils import AverageMeter, MetricsTracker
from lerobot.common.utils.train_utils import (
get_step_checkpoint_dir,
load_training_state,
save_checkpoint,
update_last_checkpoint,
)
from lerobot.common.utils.utils import get_safe_torch_device
from lerobot.scripts.train import update_policy
from lerobot.configs.train import TrainPipelineConfig

åœ¨æ¨¡å—åŠ è½½æ—¶ï¼Œç¡®ä¿æ‰€æœ‰ lerobot çš„æ’ä»¶éƒ½è¢«æ³¨å†Œ

import lerobot.common.envs.factory
import lerobot.common.policies.factory

def prepare_config(
base_config_path: str,
user_override_config: Dict[str, Any],
run_dir: str,
start_step: int,
end_step: int,
) -> TrainPipelineConfig:
"""
ç¬¬ä¸€é˜¶æ®µï¼šåŠ è½½ã€åˆå¹¶å¹¶å‡†å¤‡æœ€ç»ˆçš„è®­ç»ƒé…ç½®å¯¹è±¡ã€‚
"""
logging.info(f"Loading base config from: {base_config_path}")
logging.info(f"Applying user override config: {user_override_config}")

Generated code
# å°†ç”¨æˆ·è¦†ç›–å­—å…¸è½¬æ¢ä¸º draccus èƒ½ç†è§£çš„å‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨
overrides = []
for key, value in user_override_config.items():
    if isinstance(value, dict):
        for inner_key, inner_value in value.items():
            overrides.append(f"--{key}.{inner_key}={inner_value}")
    else:
        overrides.append(f"--{key}={value}")

# ç›´æ¥è°ƒç”¨ draccus.parse æ¥åŠ è½½å’Œåˆå¹¶
cfg: TrainPipelineConfig = draccus.parse(
    config_class=TrainPipelineConfig,
    config_path=base_config_path,
    args=overrides
)

# å¼ºåˆ¶è¦†ç›–å¹³å°ç®¡ç†çš„å‚æ•°
cfg.resume = start_step > 0
cfg.steps = user_override_config.get('steps', cfg.steps) # ä»»åŠ¡æ€»æ­¥æ•°åº”æ¥è‡ªç”¨æˆ·é…ç½®

# å¦‚æœæ•°æ®é›†å·²ç»ä¸‹è½½åˆ°æœ¬åœ°ï¼Œåˆ™è¦†ç›– repo_id
local_dataset_dir = Path(run_dir) / "dataset"
if local_dataset_dir.exists():
    cfg.dataset.repo_id = str(local_dataset_dir)

# æ‰‹åŠ¨è§¦å‘ lerobot çš„æ ¸å¿ƒé…ç½®åå¤„ç†é€»è¾‘

cfg.validate()

logging.info("Successfully created final training configuration.")
logging.info(pformat(cfg.to_dict()))
return cfg
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END
TODO resume the previous training state

def initialize_training_objects(
cfg: TrainPipelineConfig,
device: torch.device,
start_step: int,
) -> Tuple:
"""
ç¬¬äºŒé˜¶æ®µï¼šæ ¹æ®é…ç½®åˆå§‹åŒ–æ‰€æœ‰è®­ç»ƒæ‰€éœ€çš„å¯¹è±¡ã€‚
"""
logging.info("Creating dataset...")
dataset = make_dataset(cfg)

Generated code
logging.info("Creating policy...")
policy = make_policy(cfg=cfg.policy, ds_meta=dataset.meta)
policy.to(device)

logging.info("Creating optimizer and scheduler...")
optimizer, lr_scheduler = make_optimizer_and_scheduler(cfg, policy)
grad_scaler = GradScaler(device.type, enabled=cfg.policy.use_amp)

# åŠ è½½ Checkpoint (å¦‚æœæ–­ç‚¹ç»­ç»ƒ)
if start_step > 0:
    checkpoint_path = Path(cfg.output_dir) / "checkpoints" / "last"
    if checkpoint_path.is_symlink() or checkpoint_path.exists():
        logging.info(f"Resuming training from checkpoint: {checkpoint_path.resolve()}")
        loaded_step, optimizer, lr_scheduler = load_training_state(
            checkpoint_path, optimizer, lr_scheduler, policy=policy, device=device
        )
        logging.info(f"Checkpoint loaded, was at step {loaded_step}. Starting from {start_step}.")
    else:
        logging.warning(f"Expected a checkpoint at {checkpoint_path} for resuming, but not found.")

return dataset, policy, optimizer, lr_scheduler, grad_scaler
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END

def execute_training_loop(
cfg: TrainPipelineConfig,
device: torch.device,
start_step: int,
end_step: int,
training_objects: Tuple,
log_callback: Callable,
save_callback: Callable,
):
"""
ç¬¬ä¸‰é˜¶æ®µï¼šæ‰§è¡Œæ ¸å¿ƒçš„è®­ç»ƒå¾ªç¯ã€‚
"""
dataset, policy, optimizer, lr_scheduler, grad_scaler = training_objects

Generated code
# Dataloader å’Œè®­ç»ƒå‡†å¤‡
if hasattr(cfg.policy, "drop_n_last_frames"):
    sampler = EpisodeAwareSampler(
        dataset.episode_data_index, drop_n_last_frames=cfg.policy.drop_n_last_frames, shuffle=True
    )
    shuffle = False
else:
    sampler = None
    shuffle = True
    
dataloader = torch.utils.data.DataLoader(
    dataset, 
    num_workers=cfg.num_workers,
    batch_size=cfg.batch_size, 
    shuffle=shuffle, 
    sampler=sampler, 
    pin_memory=device.type != "cpu", 
    drop_last=False
)
dl_iter = cycle(dataloader)

if start_step > 0:
    logging.info(f"Fast-forwarding dataloader by {start_step} steps...")
    for _ in range(start_step):
        next(dl_iter)

policy.train()

train_metrics = {
    "loss": AverageMeter("loss", ":.3f"), "grad_norm": AverageMeter("grdn", ":.3f"), "lr": AverageMeter("lr", ":0.1e"),
    "update_s": AverageMeter("updt_s", ":.3f"), "dataloading_s": AverageMeter("data_s", ":.3f"),
}
train_tracker = MetricsTracker(
    cfg.batch_size, dataset.num_frames, dataset.num_episodes, train_metrics, initial_step=start_step
)

logging.info(f"Entering training loop from step {start_step} to {end_step}...")
for step in range(start_step, end_step):
    batch = next(dl_iter)

    for key in batch:
        if isinstance(batch[key], torch.Tensor):
            batch[key] = batch[key].to(device, non_blocking=True)

    train_tracker, output_dict = update_policy(
        train_tracker,
        policy,
        batch,
        optimizer,
        cfg.optimizer.grad_clip_norm,
        grad_scaler=grad_scaler,
        lr_scheduler=lr_scheduler,
        use_amp=cfg.policy.use_amp,
    )
    current_step = step + 1

    is_log_step = cfg.log_freq > 0 and current_step % cfg.log_freq == 0
    is_saving_step = current_step % cfg.save_freq == 0 or current_step == cfg.steps

    if is_log_step:
        log_callback(current_step, train_tracker.to_dict())
        train_tracker.reset_averages() 

    if cfg.save_checkpoint and is_saving_step:
        logging.info(f"Saving checkpoint at step {current_step}")
        checkpoint_dir = get_step_checkpoint_dir(cfg.output_dir, cfg.steps, current_step)
        logging.info(f"Saving checkpoint to: {checkpoint_dir}")
        save_checkpoint(checkpoint_dir, current_step, cfg, policy, optimizer, lr_scheduler)
        update_last_checkpoint(checkpoint_dir)
        
        save_callback(current_step, str(checkpoint_dir))

logging.info(f"Finished training slice. Final step for this slice: {end_step}")
return end_step
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END

def run_lerobot_training(
base_config_path: str,
user_override_config: Dict[str, Any],
run_dir: str,
start_step: int,
end_step: int,
log_callback: Callable,
save_callback: Callable,
):
"""
ä¸»å…¥å£å‡½æ•°ï¼Œç¼–æ’æ•´ä¸ªè®­ç»ƒæµç¨‹ã€‚
"""
# é˜¶æ®µä¸€ï¼šå‡†å¤‡é…ç½®
cfg = prepare_config(base_config_path, user_override_config, run_dir, start_step, end_step)

Generated code
# è®¾ç½®è®¾å¤‡
device = get_safe_torch_device(cfg.policy.device, log=True)
torch.backends.cudnn.benchmark = True
torch.backends.cuda.matmul.allow_tf32 = True

# é˜¶æ®µäºŒï¼šåˆå§‹åŒ–æ‰€æœ‰å¯¹è±¡
training_objects = initialize_training_objects(cfg, device, start_step)

# é˜¶æ®µä¸‰ï¼šæ‰§è¡Œè®­ç»ƒå¾ªç¯
final_step = execute_training_loop(
    cfg, device, start_step, end_step,
    training_objects, log_callback, save_callback
)



