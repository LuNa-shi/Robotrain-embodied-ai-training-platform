#!/usr/bin/env python3
"""
æµ‹è¯•ä» MinIO è·å– task_id=1 çš„æœ€å¤§ step checkpoint å¹¶ä¸‹è½½è§£å‹çš„åŠŸèƒ½
"""

import sys
import os
import asyncio
import tempfile
import shutil
import json
import time
import re
from pathlib import Path
from typing import Dict, Any, Optional, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from training_platform.common.minio_utils import (
    get_minio_client, 
    list_objects_with_prefix,
    download_ckpt_from_minio
)
from training_platform.configs.settings import settings

def setup_test_environment():
    """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
    print("ğŸ”§ è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")
    
    # åˆ›å»º outputs æ–‡ä»¶å¤¹
    outputs_dir = Path("./outputs")
    outputs_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºæµ‹è¯•ç»“æœç›®å½•
    test_results_dir = outputs_dir / "checkpoint_download_tests"
    test_results_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºä¸‹è½½ç›®å½•
    download_dir = outputs_dir / "downloaded_checkpoints"
    download_dir.mkdir(exist_ok=True)
    
    print(f"âœ… æµ‹è¯•ç»“æœç›®å½•: {test_results_dir}")
    print(f"âœ… ä¸‹è½½ç›®å½•: {download_dir}")
    
    return outputs_dir, test_results_dir, download_dir

async def test_minio_connection():
    """æµ‹è¯• MinIO è¿æ¥"""
    print("\nğŸ§ª æµ‹è¯• MinIO è¿æ¥...")
    
    try:
        client = await get_minio_client()
        
        if client:
            print("âœ… MinIO å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
            
            # æµ‹è¯•åˆ—å‡ºå­˜å‚¨æ¡¶
            buckets = await client.list_buckets()
            print(f"ğŸ“¦ å¯ç”¨å­˜å‚¨æ¡¶: {[bucket.name for bucket in buckets]}")
            
            # æ£€æŸ¥é»˜è®¤å­˜å‚¨æ¡¶
            bucket_exists = await client.bucket_exists(settings.MINIO_BUCKET)
            print(f"ğŸ“¦ é»˜è®¤å­˜å‚¨æ¡¶ '{settings.MINIO_BUCKET}' å­˜åœ¨: {bucket_exists}")
            
            if not bucket_exists:
                print(f"âŒ å­˜å‚¨æ¡¶ '{settings.MINIO_BUCKET}' ä¸å­˜åœ¨")
                return False, None
            
            return True, client
        else:
            print("âŒ MinIO å®¢æˆ·ç«¯è¿æ¥å¤±è´¥")
            return False, None
            
    except Exception as e:
        print(f"âŒ MinIO è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿ MinIO æœåŠ¡æ­£åœ¨è¿è¡Œ")
        print("ğŸ’¡ æ£€æŸ¥é…ç½®: MINIO_URL, MINIO_ACCESS_KEY, MINIO_SECRET_KEY")
        return False, None

async def find_latest_checkpoint_for_task(client, task_id: str) -> Tuple[bool, Optional[str], Optional[int], Dict[str, Any]]:
    """
    æŸ¥æ‰¾æŒ‡å®š task_id çš„æœ€æ–° checkpoint
    
    Args:
        client: MinIO å®¢æˆ·ç«¯
        task_id: è®­ç»ƒä»»åŠ¡ ID
        
    Returns:
        (success, latest_checkpoint_path, latest_step, search_info)
    """
    print(f"\nğŸ” æŸ¥æ‰¾ task_id={task_id} çš„æœ€æ–° checkpoint...")
    
    try:
        # æ„å»ºæœç´¢å‰ç¼€
        prefix = f"{settings.MINIO_CKPT_DIR}/{task_id}/"
        
        print(f"ğŸ” æœç´¢å‰ç¼€: {prefix}")
        print(f"ğŸ—‚ï¸  å­˜å‚¨æ¡¶: {settings.MINIO_BUCKET}")
        
        # åˆ—å‡ºæ‰€æœ‰ç¬¦åˆå‰ç¼€çš„å¯¹è±¡
        success, objects = await list_objects_with_prefix(
            client=client,
            bucket_name=settings.MINIO_BUCKET,
            prefix=prefix
        )
        
        if not success:
            print(f"âŒ æ— æ³•åˆ—å‡ºå¯¹è±¡ï¼Œå‰ç¼€: {prefix}")
            return False, None, None, {"error": "æ— æ³•åˆ—å‡ºå¯¹è±¡"}
        
        print(f"ğŸ“‹ æ‰¾åˆ° {len(objects)} ä¸ªå¯¹è±¡:")
        for obj in objects:
            print(f"  ğŸ“„ {obj}")
        
        # è¿‡æ»¤å‡º checkpoint æ–‡ä»¶å¹¶è§£æ step å·
        checkpoint_pattern = re.compile(rf"{re.escape(settings.MINIO_CKPT_DIR)}/{re.escape(task_id)}/checkpoint_step_(\d+)\.zip$")
        checkpoints = []
        
        for obj_name in objects:
            match = checkpoint_pattern.match(obj_name)
            if match:
                step = int(match.group(1))
                checkpoints.append((step, obj_name))
                print(f"âœ… åŒ¹é… checkpoint: step={step}, æ–‡ä»¶={obj_name}")
            else:
                print(f"âš ï¸  ä¸åŒ¹é… checkpoint æ¨¡å¼: {obj_name}")
        
        if not checkpoints:
            print(f"âŒ æ²¡æœ‰æ‰¾åˆ° task_id={task_id} çš„ checkpoint æ–‡ä»¶")
            search_info = {
                "prefix": prefix,
                "total_objects": len(objects),
                "checkpoint_count": 0,
                "all_objects": objects,
                "error": "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ ¼å¼çš„checkpointæ–‡ä»¶"
            }
            return False, None, None, search_info
        
        # æŒ‰ step æ’åºï¼Œå–æœ€å¤§çš„
        checkpoints.sort(key=lambda x: x[0], reverse=True)
        latest_step, latest_checkpoint = checkpoints[0]
        
        print(f"\nğŸ¯ å‘ç°çš„ checkpoint:")
        for step, obj_name in sorted(checkpoints, key=lambda x: x[0]):
            marker = "ğŸ‘‘ [æœ€æ–°]" if step == latest_step else "  "
            print(f"  {marker} Step {step:6d}: {obj_name}")
        
        print(f"\nğŸ† æœ€æ–° checkpoint:")
        print(f"  ğŸ“ˆ Step: {latest_step}")
        print(f"  ğŸ“„ æ–‡ä»¶: {latest_checkpoint}")
        
        search_info = {
            "prefix": prefix,
            "total_objects": len(objects),
            "checkpoint_count": len(checkpoints),
            "latest_checkpoint": latest_checkpoint,
            "latest_step": latest_step,
            "all_checkpoints": [{"step": step, "object": obj} for step, obj in checkpoints],
            "all_objects": objects
        }
        
        return True, latest_checkpoint, latest_step, search_info
        
    except Exception as e:
        print(f"âŒ æŸ¥æ‰¾ checkpoint å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        error_info = {
            "error": str(e),
            "traceback": traceback.format_exc()
        }
        return False, None, None, error_info

async def download_and_extract_checkpoint(client, checkpoint_path: str, download_dir: Path) -> Tuple[bool, Optional[Path], Dict[str, Any]]:
    """
    ä¸‹è½½å¹¶è§£å‹ checkpoint æ–‡ä»¶
    
    Args:
        client: MinIO å®¢æˆ·ç«¯
        checkpoint_path: checkpoint åœ¨ MinIO ä¸­çš„è·¯å¾„
        download_dir: æœ¬åœ°ä¸‹è½½ç›®å½•
        
    Returns:
        (success, extract_dir_path, download_info)
    """
    print(f"\nğŸ“¥ ä¸‹è½½å¹¶è§£å‹ checkpoint: {checkpoint_path}")
    
    try:
        # åˆ›å»ºä¸´æ—¶ä¸‹è½½ç›®å½•
        timestamp = int(time.time())
        temp_download_dir = download_dir / f"temp_download_{timestamp}"
        temp_download_dir.mkdir(exist_ok=True)
        
        # æ„å»ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
        checkpoint_filename = Path(checkpoint_path).name
        local_zip_path = temp_download_dir / checkpoint_filename
        
        print(f"ğŸ“ ä¸´æ—¶ä¸‹è½½ç›®å½•: {temp_download_dir}")
        print(f"ğŸ“„ æœ¬åœ°æ–‡ä»¶è·¯å¾„: {local_zip_path}")
        
        # ä¸‹è½½æ–‡ä»¶
        print("â¬‡ï¸  å¼€å§‹ä¸‹è½½...")
        download_start_time = time.time()
        
        # download_ckpt_from_minio ä¼šè‡ªåŠ¨æ·»åŠ  MINIO_CKPT_DIR å‰ç¼€
        # æ‰€ä»¥æˆ‘ä»¬éœ€è¦ç§»é™¤ checkpoint_path ä¸­çš„å‰ç¼€éƒ¨åˆ†
        from training_platform.configs.settings import settings
        
        if checkpoint_path.startswith(f"{settings.MINIO_CKPT_DIR}/"):
            # ç§»é™¤å‰ç¼€ï¼Œåªä¿ç•™ç›¸å¯¹è·¯å¾„
            relative_ckpt_path = checkpoint_path[len(f"{settings.MINIO_CKPT_DIR}/"):]
        else:
            relative_ckpt_path = checkpoint_path
        
        print(f"ğŸ”§ MinIO å¯¹è±¡è·¯å¾„: {checkpoint_path}")
        print(f"ğŸ”§ ç›¸å¯¹è·¯å¾„: {relative_ckpt_path}")
        
        success, message = await download_ckpt_from_minio(
            client=client,
            download_local_path=str(local_zip_path),
            ckpt_name=relative_ckpt_path
        )
        
        download_time = time.time() - download_start_time
        
        if not success:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {message}")
            shutil.rmtree(temp_download_dir, ignore_errors=True)
            return False, None, {"error": message, "download_time": download_time}
        
        file_size = local_zip_path.stat().st_size
        print(f"âœ… ä¸‹è½½æˆåŠŸ!")
        print(f"  ğŸ“ æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
        print(f"  â±ï¸  ä¸‹è½½æ—¶é—´: {download_time:.2f} ç§’")
        print(f"  ğŸš€ ä¸‹è½½é€Ÿåº¦: {(file_size / 1024 / 1024) / download_time:.2f} MB/s")
        
        # è§£å‹æ–‡ä»¶
        print("ğŸ“¦ å¼€å§‹è§£å‹...")
        extract_start_time = time.time()
        
        extract_dir = temp_download_dir / "extracted"
        extract_dir.mkdir(exist_ok=True)
        
        shutil.unpack_archive(str(local_zip_path), str(extract_dir))
        
        extract_time = time.time() - extract_start_time
        print(f"âœ… è§£å‹å®Œæˆ!")
        print(f"  â±ï¸  è§£å‹æ—¶é—´: {extract_time:.2f} ç§’")
        
        # åˆ†æè§£å‹å†…å®¹
        print("ğŸ” åˆ†æè§£å‹å†…å®¹...")
        extracted_items = []
        total_files = 0
        total_size = 0
        
        for root, dirs, files in os.walk(extract_dir):
            for file in files:
                file_path = Path(root) / file
                relative_path = file_path.relative_to(extract_dir)
                file_size = file_path.stat().st_size
                
                extracted_items.append({
                    "path": str(relative_path),
                    "size": file_size,
                    "size_mb": file_size / 1024 / 1024
                })
                
                total_files += 1
                total_size += file_size
        
        print(f"ğŸ“Š è§£å‹ç»Ÿè®¡:")
        print(f"  ğŸ“„ æ–‡ä»¶æ€»æ•°: {total_files}")
        print(f"  ğŸ“ æ€»å¤§å°: {total_size / 1024 / 1024:.2f} MB")
        
        # æ˜¾ç¤ºä¸»è¦æ–‡ä»¶
        print(f"ğŸ“‹ ä¸»è¦æ–‡ä»¶:")
        for item in sorted(extracted_items, key=lambda x: x['size'], reverse=True)[:10]:
            print(f"  ğŸ“„ {item['path']:<40} ({item['size_mb']:.2f} MB)")
        
        if len(extracted_items) > 10:
            print(f"  ... è¿˜æœ‰ {len(extracted_items) - 10} ä¸ªæ–‡ä»¶")
        
        # æŸ¥æ‰¾é‡è¦æ–‡ä»¶
        important_files = []
        for item in extracted_items:
            path = item['path'].lower()
            if any(keyword in path for keyword in ['config.json', 'pytorch_model', 'model.safetensors', 'train_config.json']):
                important_files.append(item)
        
        if important_files:
            print(f"ğŸ¯ é‡è¦æ–‡ä»¶:")
            for item in important_files:
                print(f"  ğŸ”‘ {item['path']}")
        
        # åˆ é™¤åŸå§‹ zip æ–‡ä»¶ä»¥èŠ‚çœç©ºé—´
        os.remove(local_zip_path)
        print(f"ğŸ—‘ï¸  å·²åˆ é™¤åŸå§‹ zip æ–‡ä»¶")
        
        download_info = {
            "checkpoint_path": checkpoint_path,
            "local_zip_path": str(local_zip_path),
            "extract_dir": str(extract_dir),
            "download_time": download_time,
            "extract_time": extract_time,
            "file_size": file_size,
            "file_size_mb": file_size / 1024 / 1024,
            "total_files": total_files,
            "total_size": total_size,
            "total_size_mb": total_size / 1024 / 1024,
            "important_files": important_files,
            "all_files": extracted_items[:50]  # åªä¿å­˜å‰50ä¸ªæ–‡ä»¶ä¿¡æ¯
        }
        
        return True, extract_dir, download_info
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å’Œè§£å‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if 'temp_download_dir' in locals():
            shutil.rmtree(temp_download_dir, ignore_errors=True)
        
        error_info = {
            "error": str(e),
            "traceback": traceback.format_exc()
        }
        return False, None, error_info

async def test_model_evaluation(extract_dir: Path, checkpoint_info: Dict[str, Any]) -> Tuple[bool, Dict[str, Any]]:
    """
    æµ‹è¯•ä¸‹è½½çš„æ¨¡å‹è¯„ä¼°åŠŸèƒ½
    
    Args:
        extract_dir: è§£å‹åçš„æ¨¡å‹ç›®å½•
        checkpoint_info: checkpoint ä¿¡æ¯
        
    Returns:
        (success, eval_results)
    """
    print(f"\nğŸ¯ æµ‹è¯•æ¨¡å‹è¯„ä¼°åŠŸèƒ½...")
    
    try:
        # å¯¼å…¥è¯„ä¼°ç›¸å…³æ¨¡å—
        from training_platform.evaluator.evaluator_logic import run_lerobot_evaluation_sync
        
        # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶å’Œé…ç½®æ–‡ä»¶
        model_files = []
        config_files = []
        pretrained_model_dir = None
        
        for root, dirs, files in os.walk(extract_dir):
            for file in files:
                file_path = os.path.join(root, file)
                
                # æŸ¥æ‰¾æ¨¡å‹æƒé‡æ–‡ä»¶
                if any(keyword in file.lower() for keyword in ['pytorch_model', 'model.safetensors', 'model.bin']):
                    model_files.append(file_path)
                
                # æŸ¥æ‰¾é…ç½®æ–‡ä»¶
                if 'config.json' in file.lower() or 'train_config.json' in file.lower():
                    config_files.append(file_path)
                    
                # æ£€æŸ¥æ˜¯å¦åœ¨ pretrained_model ç›®å½•ä¸­
                if 'pretrained_model' in root and file.lower() == 'config.json':
                    pretrained_model_dir = root
        
        print(f"ğŸ” æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_files}")
        print(f"ğŸ“‹ æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_files}")
        
        if not model_files:
            print("âš ï¸  æœªæ‰¾åˆ°æ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œè·³è¿‡è¯„ä¼°æµ‹è¯•")
            return False, {"error": "æœªæ‰¾åˆ°æ¨¡å‹æƒé‡æ–‡ä»¶"}
        
        # ç¡®å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„
        if pretrained_model_dir:
            # å¦‚æœæ‰¾åˆ°äº† pretrained_model ç›®å½•ï¼Œä½¿ç”¨å®ƒ
            model_path_for_eval = pretrained_model_dir
            print(f"âœ… ä½¿ç”¨ pretrained_model ç›®å½•: {model_path_for_eval}")
        else:
            # å¦åˆ™ä½¿ç”¨è§£å‹æ ¹ç›®å½•
            model_path_for_eval = str(extract_dir)
            print(f"âš ï¸  æœªæ‰¾åˆ° pretrained_model ç›®å½•ï¼Œä½¿ç”¨è§£å‹æ ¹ç›®å½•: {model_path_for_eval}")
            
        # æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦åŒ…å«å¿…éœ€çš„é…ç½®æ–‡ä»¶
        target_config_path = os.path.join(model_path_for_eval, "config.json")
        if not os.path.exists(target_config_path):
            print(f"âŒ ç›®æ ‡ç›®å½•ç¼ºå°‘ config.json: {target_config_path}")
            return False, {"error": f"ç›®æ ‡ç›®å½•ç¼ºå°‘ config.json: {target_config_path}"}
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶å†…å®¹
        try:
            with open(target_config_path, 'r', encoding='utf-8') as f:
                config_content = json.load(f)
            
            print(f"ğŸ“‹ config.json å†…å®¹é¢„è§ˆ:")
            for key in list(config_content.keys())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”®
                print(f"  ğŸ”‘ {key}: {str(config_content[key])[:50]}{'...' if len(str(config_content[key])) > 50 else ''}")
            
            if len(config_content) > 5:
                print(f"  ... è¿˜æœ‰ {len(config_content) - 5} ä¸ªé…ç½®é¡¹")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å« 'type' å­—æ®µï¼ˆLeRobot ç­–ç•¥é…ç½®å¿…éœ€ï¼‰
            if 'type' not in config_content:
                print(f"âš ï¸  é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„ 'type' å­—æ®µï¼Œå°è¯•æ·»åŠ é»˜è®¤å€¼")
                # å°è¯•ä»æ–‡ä»¶åæˆ–è·¯å¾„æ¨æ–­æ¨¡å‹ç±»å‹
                config_content['type'] = 'act'  # é»˜è®¤ä½¿ç”¨ ACT ç±»å‹
                
                # ä¿å­˜ä¿®æ”¹åçš„é…ç½®
                with open(target_config_path, 'w', encoding='utf-8') as f:
                    json.dump(config_content, f, indent=2)
                
                print(f"âœ… å·²æ·»åŠ é»˜è®¤ type å­—æ®µ: {config_content['type']}")
            else:
                print(f"âœ… é…ç½®æ–‡ä»¶åŒ…å« type å­—æ®µ: {config_content['type']}")
                
        except Exception as config_error:
            print(f"âŒ æ— æ³•è¯»å–æˆ–è§£æé…ç½®æ–‡ä»¶: {config_error}")
            return False, {"error": f"é…ç½®æ–‡ä»¶è§£æå¤±è´¥: {config_error}"}
        
        # å‡†å¤‡è¯„ä¼°ç¯å¢ƒé…ç½®ï¼ˆä½¿ç”¨ç®€å•çš„æµ‹è¯•é…ç½®ï¼‰
        env_config = {
            "type": "aloha",
            "task": "AlohaInsertion-v0",
            "fps": 50,
            "episode_length": 100,  # ç¼©çŸ­æµ‹è¯•æ—¶é—´
            "obs_type": "pixels_agent_pos",
            "render_mode": "rgb_array"
        }
        
        eval_config = {
            "n_episodes": 1,  # åªæµ‹è¯•1ä¸ªepisode
            "batch_size": 1,
            "use_async_envs": False
        }
        
        # åˆ›å»ºè¯„ä¼°è¾“å‡ºç›®å½•
        eval_output_dir = extract_dir.parent / "eval_test_output"
        eval_output_dir.mkdir(exist_ok=True)
        
        print(f"ğŸƒ å¼€å§‹è¯„ä¼°æµ‹è¯•...")
        print(f"  æ¨¡å‹è·¯å¾„: {model_path_for_eval}")
        print(f"  è¾“å‡ºç›®å½•: {eval_output_dir}")
        print(f"  Episodes: {eval_config['n_episodes']}")
        
        # è®°å½•å¼€å§‹æ—¶é—´
        eval_start_time = time.time()
        
        try:
            # å°è¯•è¿è¡Œè¯„ä¼°ï¼ˆè¿™å¯èƒ½ä¼šå¤±è´¥ï¼Œå› ä¸ºå¯èƒ½ç¼ºå°‘ç¯å¢ƒæˆ–å…¶ä»–ä¾èµ–ï¼‰
            eval_results = await asyncio.to_thread(
                run_lerobot_evaluation_sync,
                model_path=model_path_for_eval,
                env_config=env_config,
                eval_config=eval_config,
                output_dir=str(eval_output_dir),
                seed=1000,
                max_episodes_rendered=1,
                return_episode_data=False,
            )
            
            eval_time = time.time() - eval_start_time
            
            print(f"âœ… è¯„ä¼°æµ‹è¯•å®Œæˆ!")
            print(f"  â±ï¸  è¯„ä¼°æ—¶é—´: {eval_time:.2f} ç§’")
            
            if eval_results and 'aggregated' in eval_results:
                print(f"  ğŸ“Š è¯„ä¼°ç»“æœ: {eval_results['aggregated']}")
            
            return True, {
                "eval_time": eval_time,
                "eval_results": eval_results,
                "model_files": model_files,
                "config_files": config_files,
                "model_path_used": model_path_for_eval,
                "eval_output_dir": str(eval_output_dir)
            }
            
        except Exception as eval_error:
            eval_time = time.time() - eval_start_time
            error_msg = str(eval_error)
            
            print(f"âš ï¸  è¯„ä¼°æµ‹è¯•å¤±è´¥: {error_msg}")
            print(f"  â±ï¸  å°è¯•æ—¶é—´: {eval_time:.2f} ç§’")
            
            # è¿™ä¸ç®—ä¸¥é‡é”™è¯¯ï¼Œå› ä¸ºå¯èƒ½æ˜¯ç¯å¢ƒé—®é¢˜
            return False, {
                "eval_time": eval_time,
                "error": error_msg,
                "model_files": model_files,
                "config_files": config_files,
                "model_path_used": model_path_for_eval,
                "message": "è¯„ä¼°ç¯å¢ƒå¯èƒ½æœªæ­£ç¡®é…ç½®ï¼Œä½†æ¨¡å‹æ–‡ä»¶ç»“æ„æ­£å¸¸"
            }
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°æµ‹è¯•å‡†å¤‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        return False, {
            "error": str(e),
            "traceback": traceback.format_exc()
        }

async def close_minio_connections():
    """å…³é—­MinIOè¿æ¥ä»¥é¿å…æœªå…³é—­è¿æ¥çš„è­¦å‘Š"""
    try:
        from training_platform.common.minio_utils import _MinIOManager
        
        # è·å–ç®¡ç†å™¨å®ä¾‹
        if _MinIOManager._instance is not None:
            manager = _MinIOManager._instance
            if manager.client is not None:
                # å°è¯•å…³é—­åº•å±‚çš„HTTPä¼šè¯
                if hasattr(manager.client, '_http_session') and manager.client._http_session:
                    if hasattr(manager.client._http_session, 'close'):
                        await manager.client._http_session.close()
                    print("ğŸ”Œ å·²å…³é—­ MinIO HTTP ä¼šè¯")
                
                # æ¸…ç©ºå®¢æˆ·ç«¯å¼•ç”¨
                manager.client = None
                print("ğŸ”Œ å·²æ¸…ç† MinIO å®¢æˆ·ç«¯å¼•ç”¨")
        
        print("âœ… MinIO è¿æ¥æ¸…ç†å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  å…³é—­ MinIO è¿æ¥æ—¶å‡ºç°è­¦å‘Š: {e}")
        # è¿™ä¸æ˜¯ä¸¥é‡é”™è¯¯ï¼Œä¸è¦æŠ›å‡ºå¼‚å¸¸

async def run_checkpoint_download_test():
    """è¿è¡Œ checkpoint ä¸‹è½½æµ‹è¯•çš„ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ task_id=1 checkpoint ä¸‹è½½å’Œè§£å‹æµ‹è¯•")
    print("=" * 60)
    
    outputs_dir, test_results_dir, download_dir = setup_test_environment()
    
    # æµ‹è¯•ç»“æœè®°å½•
    test_results = {
        "test_name": "taskid_1_checkpoint_download_test",
        "start_time": time.time(),
        "task_id": "1",
        "steps": []
    }
    
    try:
        # 1. æµ‹è¯• MinIO è¿æ¥
        print(f"\n{'='*20} æ­¥éª¤ 1: MinIO è¿æ¥æµ‹è¯• {'='*20}")
        
        connection_success, client = await test_minio_connection()
        test_results["steps"].append({
            "step": 1,
            "name": "minio_connection",
            "success": connection_success,
            "timestamp": time.time()
        })
        
        if not connection_success:
            print("âŒ MinIO è¿æ¥å¤±è´¥ï¼Œæµ‹è¯•ç»ˆæ­¢")
            test_results["success"] = False
            test_results["error"] = "MinIO è¿æ¥å¤±è´¥"
            return False, test_results
        
        # 2. æŸ¥æ‰¾æœ€æ–° checkpoint
        print(f"\n{'='*20} æ­¥éª¤ 2: æŸ¥æ‰¾æœ€æ–° checkpoint {'='*20}")
        
        find_success, latest_checkpoint, latest_step, search_info = await find_latest_checkpoint_for_task(client, "1")
        test_results["steps"].append({
            "step": 2,
            "name": "find_latest_checkpoint",
            "success": find_success,
            "timestamp": time.time(),
            "data": search_info
        })
        
        if not find_success or latest_checkpoint is None:
            print("âŒ æœªæ‰¾åˆ° checkpointï¼Œæµ‹è¯•ç»ˆæ­¢")
            test_results["success"] = False
            test_results["error"] = "æœªæ‰¾åˆ°checkpointæ–‡ä»¶"
            test_results["search_info"] = search_info
            return False, test_results
        
        test_results["latest_checkpoint"] = latest_checkpoint
        test_results["latest_step"] = latest_step
        
        # 3. ä¸‹è½½å’Œè§£å‹ checkpoint
        print(f"\n{'='*20} æ­¥éª¤ 3: ä¸‹è½½å’Œè§£å‹ checkpoint {'='*20}")
        
        download_success, extract_dir, download_info = await download_and_extract_checkpoint(
            client, latest_checkpoint, download_dir
        )
        test_results["steps"].append({
            "step": 3,
            "name": "download_and_extract",
            "success": download_success,
            "timestamp": time.time(),
            "data": download_info
        })
        
        if not download_success:
            print("âŒ ä¸‹è½½å’Œè§£å‹å¤±è´¥")
            test_results["success"] = False
            test_results["error"] = "ä¸‹è½½å’Œè§£å‹å¤±è´¥"
            test_results["download_info"] = download_info
            return False, test_results
        
        test_results["extract_dir"] = str(extract_dir)
        test_results["download_info"] = download_info
        
        # 4. æ¨¡å‹è¯„ä¼°æµ‹è¯•
        print(f"\n{'='*20} æ­¥éª¤ 4: æ¨¡å‹è¯„ä¼°æµ‹è¯• {'='*20}")
        
        if extract_dir is None:
            print("âŒ æ— æ³•è¿›è¡Œè¯„ä¼°æµ‹è¯•ï¼šè§£å‹ç›®å½•ä¸ºç©º")
            eval_success, eval_info = False, {"error": "è§£å‹ç›®å½•ä¸ºç©º"}
        else:
            eval_success, eval_info = await test_model_evaluation(extract_dir, download_info)
        test_results["steps"].append({
            "step": 4,
            "name": "model_evaluation",
            "success": eval_success,
            "timestamp": time.time(),
            "data": eval_info
        })
        
        test_results["eval_info"] = eval_info
        
        if eval_success:
            print("âœ… æ¨¡å‹è¯„ä¼°æµ‹è¯•æˆåŠŸ")
        else:
            print("âš ï¸  æ¨¡å‹è¯„ä¼°æµ‹è¯•å¤±è´¥ï¼ˆè¿™å¯èƒ½æ˜¯ç”±äºç¯å¢ƒé…ç½®é—®é¢˜ï¼‰")
        
        # 5. æµ‹è¯•å®Œæˆ
        test_results["success"] = True
        test_results["end_time"] = time.time()
        test_results["total_time"] = test_results["end_time"] - test_results["start_time"]
        
        print(f"\n{'='*60}")
        print("ğŸ‰ æµ‹è¯•æˆåŠŸå®Œæˆ!")
        print(f"âœ… æ€»è€—æ—¶: {test_results['total_time']:.2f} ç§’")
        print(f"âœ… æœ€æ–°æ¨¡å‹: Step {latest_step}")
        print(f"âœ… æ¨¡å‹å¤§å°: {download_info['file_size_mb']:.2f} MB")
        print(f"âœ… æ–‡ä»¶æ•°é‡: {download_info['total_files']}")
        print(f"âœ… è§£å‹ç›®å½•: {extract_dir}")
        if eval_success:
            print(f"âœ… è¯„ä¼°æµ‹è¯•: æˆåŠŸ")
        else:
            print(f"âš ï¸  è¯„ä¼°æµ‹è¯•: å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ç¯å¢ƒé—®é¢˜ï¼‰")
        print(f"{'='*60}")
        
        return True, test_results
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        
        test_results["success"] = False
        test_results["error"] = str(e)
        test_results["traceback"] = traceback.format_exc()
        test_results["end_time"] = time.time()
        
        return False, test_results
    
    finally:
        # å…³é—­ MinIO è¿æ¥
        await close_minio_connections()
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        results_file = test_results_dir / f"checkpoint_download_test_{int(time.time())}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(test_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜: {results_file}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        success, test_results = asyncio.run(run_checkpoint_download_test())
        
        if success:
            print("\nğŸŠ task_id=1 checkpoint ä¸‹è½½æµ‹è¯•æˆåŠŸ!")
            print("ğŸ“¦ å¯ä»¥æˆåŠŸä» MinIO è·å–å¹¶è§£å‹æœ€æ–°çš„è®­ç»ƒæ¨¡å‹ã€‚")
        else:
            print("\nâŒ task_id=1 checkpoint ä¸‹è½½æµ‹è¯•å¤±è´¥ã€‚")
            
            if "search_info" in test_results:
                search_info = test_results["search_info"]
                if "total_objects" in search_info:
                    print(f"ğŸ’¡ æ‰¾åˆ° {search_info['total_objects']} ä¸ªå¯¹è±¡ï¼Œä½†å…¶ä¸­ {search_info.get('checkpoint_count', 0)} ä¸ªæ˜¯æœ‰æ•ˆçš„ checkpoint")
                if "all_objects" in search_info and search_info["all_objects"]:
                    print("ğŸ’¡ MinIO ä¸­å­˜åœ¨çš„æ–‡ä»¶:")
                    for obj in search_info["all_objects"][:5]:
                        print(f"  ğŸ“„ {obj}")
                    if len(search_info["all_objects"]) > 5:
                        print(f"  ... è¿˜æœ‰ {len(search_info['all_objects']) - 5} ä¸ªæ–‡ä»¶")
        
        return 0 if success else 1
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿è¡Œå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 